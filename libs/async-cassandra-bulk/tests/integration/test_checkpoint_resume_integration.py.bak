"""
Integration tests for checkpoint and resume functionality.

What this tests:
---------------
1. Checkpoint saves complete export state including writetime config
2. Resume continues from exact checkpoint position
3. No data duplication or loss on resume
4. Configuration validation on resume

Why this matters:
----------------
- Production exports can fail and need resuming
- Data integrity must be maintained
- Configuration consistency is critical
- Writetime settings must persist
"""

import asyncio
import csv
import json
import os
import tempfile
import time
from pathlib import Path
from typing import Dict, List, Optional

import pytest

from async_cassandra_bulk import BulkOperator
from async_cassandra_bulk.parallel_export import ParallelExporter
from async_cassandra_bulk.exporters import CSVExporter


class TestCheckpointResumeIntegration:
    """Test checkpoint and resume functionality with real interruptions."""

    @pytest.fixture
    async def checkpoint_test_table(self, session):
        """
        Create table with enough data to test checkpointing.

        What this tests:
        ---------------
        1. Table large enough to checkpoint multiple times
        2. Multiple token ranges for parallel processing
        3. Writetime data to verify preservation
        4. Predictable data for verification

        Why this matters:
        ----------------
        - Need multiple checkpoints to test properly
        - Token ranges test parallel resume
        - Writetime config must persist
        - Data verification critical
        """
        table_name = "checkpoint_resume_test"
        keyspace = "test_bulk"

        await session.execute(
            f"""
            CREATE TABLE IF NOT EXISTS {keyspace}.{table_name} (
                partition_id INT,
                row_id INT,
                data TEXT,
                status TEXT,
                value DOUBLE,
                PRIMARY KEY (partition_id, row_id)
            )
        """
        )

        # Insert 1k rows across 20 partitions (reduced for faster testing)
        insert_stmt = await session.prepare(
            f"""
            INSERT INTO {keyspace}.{table_name}
            (partition_id, row_id, data, status, value)
            VALUES (?, ?, ?, ?, ?)
            USING TIMESTAMP ?
            """
        )

        base_writetime = 1700000000000000

        for partition in range(20):
            for row in range(50):
                writetime = base_writetime + (partition * 100000) + (row * 1000)
                values = (
                    partition,
                    row,
                    f"data_{partition}_{row}",
                    "active" if partition % 2 == 0 else "inactive",
                    partition * 100.0 + row,
                    writetime,
                )
                await session.execute(insert_stmt, values)

        yield f"{keyspace}.{table_name}"

        await session.execute(f"DROP TABLE IF EXISTS {keyspace}.{table_name}")

    @pytest.mark.asyncio
    async def test_checkpoint_resume_basic(self, session, checkpoint_test_table):
        """
        Test basic checkpoint and resume functionality.

        What this tests:
        ---------------
        1. Checkpoints are created during export
        2. Resume skips already processed ranges
        3. Final row count matches expected
        4. No duplicate data in output

        Why this matters:
        ----------------
        - Basic functionality must work
        - Checkpoint format must be correct
        - Resume must be efficient
        - Data integrity critical
        """
        # First, get a partial checkpoint by limiting the export
        partial_checkpoint = None

        def save_partial_checkpoint(data):
            nonlocal partial_checkpoint
            # Save checkpoint after processing some data
            if data["total_rows"] > 300 and partial_checkpoint is None:
                partial_checkpoint = data.copy()

        with tempfile.NamedTemporaryFile(mode="w", suffix=".csv", delete=False) as tmp:
            output_path = tmp.name

        try:
            operator = BulkOperator(session=session)

            # First export to get a partial checkpoint
            print("\nStarting first export to create partial checkpoint...")
            stats1 = await operator.export(
                table=checkpoint_test_table,
                output_path=output_path,
                format="csv",
                concurrency=2,
                checkpoint_interval=2,  # Frequent checkpoints
                checkpoint_callback=save_partial_checkpoint,
                options={
                    "writetime_columns": ["data", "status"],
                },
            )

            # Should have created partial checkpoint
            assert partial_checkpoint is not None
            assert partial_checkpoint["total_rows"] > 300
            assert partial_checkpoint["total_rows"] < 1000

            # Verify checkpoint structure
            assert "version" in partial_checkpoint
            assert "completed_ranges" in partial_checkpoint
            assert "export_config" in partial_checkpoint
            assert partial_checkpoint["export_config"]["writetime_columns"] == ["data", "status"]

            print(f"Created partial checkpoint at {partial_checkpoint['total_rows']} rows")

            # Now start fresh export with resume from partial checkpoint
            with tempfile.NamedTemporaryFile(mode="w", suffix=".csv", delete=False) as tmp2:
                output_path2 = tmp2.name

            checkpoint_count = 0

            def save_checkpoint(data):
                nonlocal checkpoint_count
                checkpoint_count += 1

            print("\nResuming export from partial checkpoint...")
            stats2 = await operator.export(
                table=checkpoint_test_table,
                output_path=output_path2,
                format="csv",
                concurrency=2,
                checkpoint_callback=save_checkpoint,
                resume_from=partial_checkpoint,  # Resume from partial checkpoint
                options={
                    "writetime_columns": ["data", "status"],  # Same config
                },
            )

            # Should complete successfully
            assert stats2.rows_processed == 1000

            # Verify all data exported
            with open(output_path2, "r") as f:
                reader = csv.DictReader(f)
                rows_second = list(reader)

            assert len(rows_second) == 1000

            # Verify writetime columns present
            sample_row = rows_second[0]
            assert "data_writetime" in sample_row
            assert "status_writetime" in sample_row

            print(f"Resume completed with {len(rows_second)} total rows")

        finally:
            Path(output_path).unlink(missing_ok=True)
            if 'output_path2' in locals():
                Path(output_path2).unlink(missing_ok=True)

    @pytest.mark.asyncio
    async def test_checkpoint_resume_with_interruption(self, session, checkpoint_test_table):
        """
        Test checkpoint/resume with actual interruption mid-export.

        What this tests:
        ---------------
        1. Export can be cancelled mid-process
        2. Checkpoint captures partial progress
        3. Resume completes remaining work
        4. No data duplication across runs

        Why this matters:
        ----------------
        - Real failures happen mid-export
        - Must handle graceful cancellation
        - Resume must be exact
        - Production reliability
        """
        with tempfile.NamedTemporaryFile(mode="w", suffix=".csv", delete=False) as tmp:
            output_path = tmp.name

        checkpoint_data = None
        rows_at_interrupt = 0

        def save_checkpoint_interrupt(data):
            nonlocal checkpoint_data, rows_at_interrupt
            checkpoint_data = data.copy()
            rows_at_interrupt = data["total_rows"]

            # Interrupt after processing some rows
            if data["total_rows"] > 2000:
                raise KeyboardInterrupt("Simulating interruption")

        try:
            operator = BulkOperator(session=session)

            # First export - will be interrupted
            print("\nStarting export with planned interruption...")

            try:
                stats1 = await operator.export(
                    table=checkpoint_test_table,
                    output_path=output_path,
                    format="csv",
                    concurrency=2,
                    checkpoint_interval=3,  # Frequent checkpoints
                    checkpoint_callback=save_checkpoint_interrupt,
                    options={
                        "writetime_columns": ["data", "status", "value"],
                    },
                )
                assert False, "Export should have been interrupted"
            except KeyboardInterrupt:
                print(f"Export interrupted at {rows_at_interrupt} rows")

            # Should have checkpoint data
            assert checkpoint_data is not None
            assert rows_at_interrupt > 0
            assert rows_at_interrupt < 1000  # Didn't complete

            # Count partial rows
            with open(output_path, "r") as f:
                reader = csv.DictReader(f)
                partial_rows = list(reader)

            print(f"Partial export has {len(partial_rows)} rows")

            # Now resume with a new file
            with tempfile.NamedTemporaryFile(mode="w", suffix=".csv", delete=False) as tmp2:
                output_path2 = tmp2.name

            print("\nResuming from interruption checkpoint...")
            stats2 = await operator.export(
                table=checkpoint_test_table,
                output_path=output_path2,
                format="csv",
                concurrency=2,
                resume_from=checkpoint_data,
                options={
                    "writetime_columns": ["data", "status", "value"],
                },
            )

            # Should complete all rows
            assert stats2.rows_processed == 1000

            # Verify complete export
            with open(output_path2, "r") as f:
                reader = csv.DictReader(f)
                complete_rows = list(reader)

            assert len(complete_rows) == 1000

            # Verify no missing partitions
            partitions_seen = {int(row["partition_id"]) for row in complete_rows}
            assert len(partitions_seen) == 100  # All partitions present

            # Verify writetime preserved
            for row in complete_rows[:10]:
                assert row["data_writetime"]
                assert row["status_writetime"]
                assert row["value_writetime"]

        finally:
            Path(output_path).unlink(missing_ok=True)
            if 'output_path2' in locals():
                Path(output_path2).unlink(missing_ok=True)

    @pytest.mark.asyncio
    async def test_checkpoint_config_validation(self, session, checkpoint_test_table):
        """
        Test configuration validation when resuming.

        What this tests:
        ---------------
        1. Warnings when config changes on resume
        2. Different writetime columns detected
        3. Column list changes detected
        4. Table changes detected

        Why this matters:
        ----------------
        - Config consistency important
        - User mistakes happen
        - Clear warnings needed
        - Prevent silent errors
        """
        with tempfile.NamedTemporaryFile(mode="w", suffix=".csv", delete=False) as tmp:
            output_path = tmp.name

        checkpoint_data = None

        def save_checkpoint(data):
            nonlocal checkpoint_data
            checkpoint_data = data.copy()

        try:
            operator = BulkOperator(session=session)

            # First export with specific config
            await operator.export(
                table=checkpoint_test_table,
                output_path=output_path,
                format="csv",
                concurrency=2,
                checkpoint_interval=10,
                checkpoint_callback=save_checkpoint,
                columns=["partition_id", "row_id", "data", "status"],  # Specific columns
                options={
                    "writetime_columns": ["data"],  # Only data writetime
                },
            )

            assert checkpoint_data is not None

            # Verify checkpoint has config
            assert checkpoint_data["export_config"]["columns"] == ["partition_id", "row_id", "data", "status"]
            assert checkpoint_data["export_config"]["writetime_columns"] == ["data"]

            # Now resume with DIFFERENT config
            # This should work but log warnings
            with tempfile.NamedTemporaryFile(mode="w", suffix=".csv", delete=False) as tmp2:
                output_path2 = tmp2.name

            print("\nResuming with different configuration...")

            # Resume with different writetime columns - should log warning
            stats = await operator.export(
                table=checkpoint_test_table,
                output_path=output_path2,
                format="csv",
                resume_from=checkpoint_data,
                columns=["partition_id", "row_id", "data", "status", "value"],  # Added column
                options={
                    "writetime_columns": ["data", "status"],  # Different writetime
                },
            )

            # Should still complete
            assert stats.rows_processed == 1000

            # The export should use the NEW configuration
            with open(output_path2, "r") as f:
                reader = csv.DictReader(f)
                headers = reader.fieldnames

            # Should have the new columns
            assert "value" in headers
            assert "data_writetime" in headers
            assert "status_writetime" in headers  # New writetime column

        finally:
            Path(output_path).unlink(missing_ok=True)
            if 'output_path2' in locals():
                Path(output_path2).unlink(missing_ok=True)

    @pytest.mark.asyncio
    async def test_checkpoint_with_failed_ranges(self, session, checkpoint_test_table):
        """
        Test checkpoint behavior when some ranges fail.

        What this tests:
        ---------------
        1. Failed ranges not marked as completed
        2. Resume retries failed ranges
        3. Checkpoint state consistent
        4. Error handling preserved

        Why this matters:
        ----------------
        - Network errors happen
        - Failed ranges must retry
        - State consistency critical
        - Error recovery important
        """
        # This test would require injecting failures into specific ranges
        # For now, we'll test the checkpoint structure for failed scenarios

        with tempfile.NamedTemporaryFile(mode="w", suffix=".json", delete=False) as tmp:
            output_path = tmp.name

        checkpoints = []

        def track_checkpoints(data):
            checkpoints.append(data.copy())

        try:
            operator = BulkOperator(session=session)

            # Export with frequent checkpoints
            stats = await operator.export(
                table=checkpoint_test_table,
                output_path=output_path,
                format="json",
                concurrency=4,
                checkpoint_interval=2,  # Very frequent
                checkpoint_callback=track_checkpoints,
                options={
                    "writetime_columns": ["*"],
                },
            )

            # Verify multiple checkpoints created
            assert len(checkpoints) > 3

            # Verify checkpoint progression
            rows_progression = [cp["total_rows"] for cp in checkpoints]

            # Each checkpoint should have more rows
            for i in range(1, len(rows_progression)):
                assert rows_progression[i] >= rows_progression[i-1]

            # Verify ranges marked as completed
            completed_progression = [len(cp["completed_ranges"]) for cp in checkpoints]

            # Completed ranges should increase
            for i in range(1, len(completed_progression)):
                assert completed_progression[i] >= completed_progression[i-1]

            # Final checkpoint should have all data
            final_checkpoint = checkpoints[-1]
            assert final_checkpoint["total_rows"] == 1000

            print(f"\nCheckpoint progression:")
            for i, cp in enumerate(checkpoints):
                print(f"  Checkpoint {i}: {cp['total_rows']} rows, {len(cp['completed_ranges'])} ranges")

        finally:
            Path(output_path).unlink(missing_ok=True)

    @pytest.mark.asyncio
    async def test_checkpoint_atomicity(self, session, checkpoint_test_table):
        """
        Test checkpoint atomicity and consistency.

        What this tests:
        ---------------
        1. Checkpoint data is complete
        2. No partial checkpoint states
        3. Async checkpoint handling
        4. Checkpoint format stability

        Why this matters:
        ----------------
        - Corrupt checkpoints catastrophic
        - Atomic writes important
        - Format must be stable
        - Async handling tricky
        """
        output_path = None
        json_checkpoints = []

        async def async_checkpoint_handler(data):
            """Async checkpoint handler to test async support."""
            # Simulate async checkpoint save (e.g., to S3)
            await asyncio.sleep(0.01)
            json_checkpoints.append(json.dumps(data, indent=2))

        try:
            with tempfile.NamedTemporaryFile(mode="w", suffix=".csv", delete=False) as tmp:
                output_path = tmp.name

            operator = BulkOperator(session=session)

            # Export with async checkpoint handler
            stats = await operator.export(
                table=checkpoint_test_table,
                output_path=output_path,
                format="csv",
                concurrency=3,
                checkpoint_interval=5,
                checkpoint_callback=async_checkpoint_handler,
                options={
                    "writetime_columns": ["data"],
                },
            )

            assert stats.rows_processed == 1000
            assert len(json_checkpoints) > 0

            # Verify all checkpoints are valid JSON
            for cp_json in json_checkpoints:
                checkpoint = json.loads(cp_json)

                # Verify required fields
                assert "version" in checkpoint
                assert "completed_ranges" in checkpoint
                assert "total_rows" in checkpoint
                assert "export_config" in checkpoint
                assert "timestamp" in checkpoint

                # Verify types
                assert isinstance(checkpoint["completed_ranges"], list)
                assert isinstance(checkpoint["total_rows"], int)
                assert isinstance(checkpoint["export_config"], dict)

                # Verify export config
                config = checkpoint["export_config"]
                assert config["table"] == checkpoint_test_table
                assert config["writetime_columns"] == ["data"]

            # Test resuming from JSON checkpoint
            last_checkpoint = json.loads(json_checkpoints[-1])

            with tempfile.NamedTemporaryFile(mode="w", suffix=".csv", delete=False) as tmp2:
                output_path2 = tmp2.name

            # Resume from JSON-parsed checkpoint
            stats2 = await operator.export(
                table=checkpoint_test_table,
                output_path=output_path2,
                format="csv",
                resume_from=last_checkpoint,
                options={
                    "writetime_columns": ["data"],
                },
            )

            # Should complete immediately since already done
            assert stats2.rows_processed == 1000

        finally:
            if output_path:
                Path(output_path).unlink(missing_ok=True)
            if 'output_path2' in locals():
                Path(output_path2).unlink(missing_ok=True)
